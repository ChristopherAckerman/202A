#+TITLE: Econ202A Notes
#+AUTHOR: Chris Ackerman
#+LATEX_HEADER: \usepackage{amsthm}
#+LATEX_HEADER: \usepackage{url}
#+LATEX_HEADER: \usepackage[margin=1.25in]{geometry}
#+LATEX_HEADER: \usepackage{hyperref} 
#+LATEX_HEADER: \usepackage[dvipsnames]{xcolor}
#+LATEX_HEADER: \usepackage{booktabs}
#+LATEX_HEADER: \usepackage{enumitem}
#+LATEX_HEADER: \newtheorem*{definition}{Definition}
#+LATEX_HEADER: \newtheorem*{example}{Example}
#+LATEX_HEADER: \newtheorem*{theorem}{Theorem}
#+LATEX_HEADER: \newtheorem*{corollary}{Corollary}
#+LATEX_HEADER: \newtheorem*{exercise}{Exercise}
#+LATEX_HEADER: \newtheorem*{problem}{Problem}
#+LATEX_HEADER: \newtheorem{question}{Question}
#+LATEX_HEADER: \newcommand{\gr}{\textcolor{ForestGreen}}
#+LATEX_HEADER: \newcommand{\rd}{\textcolor{red}}
#+LATEX_HEADER: \newcommand{\R}{\mathbb{R}}
#+LATEX_HEADER: \newcommand{\p}{\mathbb{P}}
#+LATEX_HEADER: \newcommand{\frall}{\ \forall}
#+OPTIONS:  ':t

\newpage

* Lecture 1---October 5, 2020

Emphasis will be on neoclassical models of macroeconomic growth.

Office hours after class. Cohort effects are huge; spend lots of time collaborating with classmates. Start with certainty; converge to a single point steady state. With stochastic elements, we converge to a distribution. In both cases, we're studying an optimization problem. The model we're studying is the solution to an optimization problem. We will then discuss how to interpret these solutions as competitive equilibria. In these models, what is chosen by the planner and the competitive outcome are the same. In more realistic models, this won't be the case---there will be distortions. The goal is not to be theoretically rigorous; the focus is on applied macroeconomics---applying macroeconomic tools to study *the real world*. How can we use our theoretical models to interpret the real world or do interesting policy experiments?

** Basic Neoclassical Growth Model Cass-Koopmans)
Economy consists of many identical infinitely lived households, each with the same preferences and endowments. There are several possible interpretations
\begin{itemize}
\item Representative Agent
\item Benevolent Social Planner
\item Infinitely Lived family
\end{itemize}
There is one production sector, and output is produced from capital and labor. Output can be either consumed or invested. There is only one type of output.

Investment becomes productive capital the following period:

\[
\max \sum^\infty_{t = 0} \beta^t u(c_t), \quad 0 < \beta < 0
\]
subject to

\begin{align*}
c_t + i_t \le y_t &= F(k_t, n_t) \tag{resource constraint}\\
k_{t + 1} &\le (1 - \delta)k_t + i_t, \quad 0 < \delta \le 1\\
0 \le n_t &\le 1\\
k &=\ \text{ given}
\end{align*}
Note that these are resource constraints, not budget constraints. They're different, and commonly confused. There are /no prices/ here! $\delta$ is depreciation and $\beta$ is a discount factor. The values for these terms are related to the length of time periods, $t$.

We make some assumptions about the objects in our model. 

The production function $F: \R^2_+ \to \R^+$ is

\begin{enumerate}
\item continuously differentiable
\item Homogeneous of degree  1 $\equiv$ constant returns to scale
\item Strictly quasi-concave
\item \begin{align*}
      F(0, n) &= 0 \tag{capital is essential}\\
F_k &= \text{ marginal product of capital}\\
&> 0 \\
F_n &> 0 \tag{ marginal product of labor }\\
 \end{align*}
\item INADA conditions
\[
\lim_{k \to 0} F_k(k, 1) = \infty \quad \lim_{k \to \infty} F_k(k, 1) = 0
\]
\end{enumerate}

The utility function $u: \R_+ \to \R$ is
\begin{itemize}
\item Bounded---important for dynamic programming
\item Continuously differentiable
\item Strictly concave
\item $\lim_{c \to 0} u'(c) = \infty$
\end{itemize}

*Note*: We will use functional forms for $F$ and $u$ for almost everything in this class.

We make a few assumptions to simply the planners problem:
\begin{enumerate}
\item $F_n > 0 \implies n_t = 1$ for all $t$ and $u'(c) > 0$. We will introduce leisure in the utility function later.
\item $u'(c) > 0 \implies$ the resource constraint holds with equality,
\[
c_t + i_t = F(k_t, n_t)
\]
\item $\beta < 1 \implies$ a positive rate of return from giving up consumption today for consumption tomorrow; (actually $MP_k + 1 - \delta$)
\[
\implies k_t + 1 = (1 - \delta) k_t + i_t
\] 
\item Let
\[
f(k) \equiv F(k, 1) + (1 - \delta)k
\]
\end{enumerate}
We can now rewrite this problem as choosing a sequence of capital of stocks:
\begin{align*}
\max_{\{k_{t + 1}\}^\infty_{t = 0}}&\ \sum^\infty_{t = 0} \beta^t u(f(k_t) - k_{t +1})\\
0 \le k_{t + 1} &\le f(k_t)
\end{align*}
where $k_0$ is given.
\begin{itemize}
\item This is called a "sequence problem" by Stokey and Lucas
\item There are infinitely many choice variables, so this problem is very hard to solve.
\item Instead we can use dynamic programming. We will solve the problem recursively, and therefore there's only one choice variable (next period's capital).
\end{itemize}

** Dynamic Programming

\begin{align*}
\intertext{Let }
V(k_0) &\equiv \max_{\{k_{t+1}\}{t = 0}^\infty} \sum^\infty_{t = 0} \beta^t u(f(k_t) - k_{t + 1})\\
\intertext{given $k_0$. We are maximizing the discounted utility given $k_0$. Rewrite as}
V(k_0) &= \max_{\{k_{t+1}\}_{t = 0}^\infty} \left\{ u(f(k_0) - k_1) + \beta \sum^\infty_{t = 1} \beta^{t - 1} u(f(k_t) - k_{t + 1})\right\}\\
&= \max_{k_1} \{u(f(k_0) - k_1) + \beta V (k_1)\}\\
\intertext{where}
V(k_1) &= \max_{\{k_{t + 1}\}^\infty_{t = 1}} \sum^\infty_{t = 1}\beta^{t - 1} u(f(k_t) - k_{t + 1})
\end{align*}

*** Bellman's Equation

\[
V(k) = \max_{k'} \left\{ u(f(k) - k') + \beta V(k')\right\}
\]
This is a functional equation where the unknown is $V(k)$. $V(k)$ is called the /value function/. $u(f(k) - k')$ is called the ``return function''. Our First Order Condition is
\[
u'(f(k) - k') = \beta V'(k').
\]
We want to solve for
\[
k' = g(k),
\]
which is the /policy function/, often called the /optimal policy function/ or /decision rule/. Later we'll prove that we can take FOCs because the function is differentiable.


*** Solving for $V(k)$
\begin{enumerate}
\item Guess a function $V_0(k)$.
\item Create a new function by applying a mapping to $V_0(k)$. We apply the operator $T$, so the new function is
\[
T(v_0(k)) = \max_{k'} \left\{u(f(k) - k') +_ \beta V_0(k')\right\}
\]
\item Let 
\[
V_1(k) = T(V_0(k))
\]
\item Repeat, forming a sequence of functions where 
\[
V_n(k) = T(V_{n - 1}(k)),
\]
creating (with a computer) the sequence $\{V_n\}^\infty_{n = 0}$, where each $V_n$ is a function.
\item Continue creating functions until $V_{n - 1}(k)$ and $V_n(k)$ are the same, or close enough for the desired error term.
\end{enumerate}
It turns out that this sequence is a Cauchy sequence, so we're guaranteed to get solutions that are arbitrarily close together. Look up contraction mappings, etc.

* Lecture 2---October 7, 2020
  The $T$ we discussed yesterday is known as the /Bellman Operator/.
  

  Very few cases exists where we can fin a fixed point analytically. We can find a fixed point analytically when the return function is quadratic and the constraints are linear. If a closed form exists, we can find it use the /method of undetermined coefficients/. This is Problem 1 in our homework, and involves two steps.

\begin{enumerate}
\item Find the functional form for $V$. For example, if $V_n(k)$ is quadratic and $T(V_n(k))$ is quadratic, $V(k)$ must be quadratic.
\item Find the parameter of the fixed point.
\end{enumerate}

If the operator takes in a quadratic function and outputs a quadratic function, we know the limit must be a quadratic function, so we can guess a quadratic solution and find the parameters. For the homework, think about log-linear functional forms.

\begin{example}
Suppose
\[
V_n(k) = ak^2 + bk + c
\]
and
\[
T(V_n(k)) = \tilde{a}k^2 + \tilde{b}k + c.
\]
$T$ transofrms a quadratic function into another quadratic function, so the fixed point is a quadratic function. How do we find the fixed point? It must be the case that
\begin{align*}
\tilde{a} &= f_1(a, b, c)\\
\tilde{b} &= f_2(a, b, c)\\
\tilde{c} &= f_3(a, b, c)\\
\end{align*}
Now we're solving a system of three equations in three unknowns. How do we know if $v$ (the fixed point) exists and is unique? We will use a few concepts from Stokey and Lucas, Chapter 3.
\end{example}

\begin{theorem}[Contraction Mapping Theorem]
If $(S, \rho)$ is a complete metric space and $T: S \to S$ is a contraction mapping with modulus $\beta$, then
\begin{enumerate}
\item $T$ has exactly one fixed point $V \in S$, and
\item for any $v_0 \in S$, $\rho(T^nV_0, V) \le \beta^n \rho (V_0, V)$ for $n = 0, 1, 2 \ldots$
\end{enumerate}
\end{theorem}
Since we've defined $\beta$ such that $0 \le \beta < 1$, we can get arbitrarily close to the fixed point by sending $n \to \infty$.

\begin{itemize}
\item $S$ is a sequence of functions
\item $\rho$ is a measure of distance between two points in $S$ (a metric)
\item A Cauchy sequence is a sequence $\{V_n\}^\infty_{n = 1}$ of elements of $S$ where, for all $\varepsilon > 0$, there exists $N_\varepsilon$ such that $\rho(V_n, V_m) < \varepsilon$ for all $n, m > N_\varepsilon$.
\item Complete---every Cauchy sequence in $S$ converges to some element of $S$.
\end{itemize}

\begin{definition}[Contraction Mapping]
A \gr{contraction mapping} $T: S \to S$ is a contraction if, for some $\beta \in (0, 1)$,
\[
\rho(Tx, Ty) \le \beta \rho(x, y)
\]
for any $x, y \in S$.
\end{definition}

A \gr{fixed point} is some $v \in S$ such that $Tv = v$.

*Problem*: While the theorem guarantees that iterating on Bellman's equation will provide a sequence of functions that converges to a unique fixed point, verifying the conditions of the theorem is hard.

\begin{theorem}[Blackwell's Sufficient Condition for a Contraction]
Let $X \subseteq \R^n$ and $B(X)$ be a space of \underline{bounded functions} $f: X \to \R$ with the $\sup$ norm, $\|f\| = \sup_x |f(x)|$. Let $T: B(x) \to B(x)$ satisfy
\begin{enumerate}
\item 
\[
f, g \in B(x) \land f(x) \le g(x) \frall x \in X \implies (Tf)(x) \le (Tg)(x) \frall x \in X \tag{monotonicity}
\]
In words, if we have two functions that satisfy the initial assumption on the left, the Bellman operator preserves this ordering.
\item There exists some $\beta \in (0, 1)$ such that 
\[
[T(f + a)](x) \le (Tf)(x) + \beta a \tag{discounting}
\]
for all $f \in B(X)$ and $a \ge 0$.
\end{enumerate}
\end{theorem}

Intuitively, $T$ is the sum of two functions: the current return and the future return. We need these functions to get closer and closer to a fixed point. It is sufficient to replace a general bounded function with this scalar and then show that this is a contraction.

\begin{exercise}
Verify that the Bellman mapping
\[
T: B(X) \to B(X)
\]
from the neoclassical growth model satisfies monotonicity and discounting.
\end{exercise}

** Envelope Condition and Euler Equation
The FOC for the right hand side of the Bellman equation is
\[
u'(f(k) - g(k)) = \beta V'(g(k)),
\]
where $k' = g(k)$. The goal here is to go from our sequence problem to the Euler equation. We can get the Euler equation FOC directly by taking derivatives of the sequence problem. Note that the Bellman operator maps concave functions to concave functions.

\begin{theorem}[Envelope Theorem]
Suppose $v$ is concave and $w$ is concave and differentiable with
\[
w(x_0) = v(x_0) \text{ and } w(x) \le v(x)
\]
for all $x$ in a neighborhood of $x_0$. Then $v$ is differentiable at $x_0$ and
\[
v_i (x_0) = w_i (x_0).
\]
\end{theorem}
$v$ is a function we don't necessarily know, but we know it is concave. $w$ is a function we are going to make up. We want it to be concave and differentiable, and we want the two functions to be exactly the same at $x_0$. If we form $w$ this way, we know we can take its derivative, since we designed it to be differentiable. If we take the $i^{\text{th}}$ partial of $w$ and evaluate it at $x_0$, then its $i^{\text{th}}$ partial derivative is exactly the same as the $i^{\text{th}}$ partial of $v$. In the case of the Bellman mapping, let
\begin{align*}
w(k) &\equiv u(f(k) - g(k_0)) + \beta V(g(k_0))\\
\implies w(k_0) &= (k_0)\\
w(k) &\le v(k) \text{ for } k \text{ near } k_0.
\end{align*}
Intuitively, we're holding the future fixed and the only thing that's moving is the current capital stock. We only require this condition to hold locally; the picture below is a zoomed-in version of the Envelope Theorem. We aren't assuming anything about the behavior of either of these functions anywhere else.

# \begin{center}
# \includegraphics[width=0.75\textwidth, keepaspectratio=true]{figures/envelope_theorem.pdf}
# \end{center}
[[./figures/envelope_theorem.pdf]]

\begin{definition}[Envelope Condition]
\[
V'(k_0) = w'(k_0) = u'(f(k_0) - g(k_0))f'(k_0) \tag{chain rule}
\]
in general,
\[
v'(k) = u'(f(k) - g(k))f'(k).
\]
We can characterize the derivative of the value function without knowing the value function. Combine these two equations, and we get
\[
u'(f(k) - g(k)) = \beta u'(f(g(k)) - g(g(k)))f'(g(k))
\]
or
\[
u'(f(k_t) - k_{t + 1}) = \beta u'(f(k_{t + 1}) - k_{t + 2})f'(k_{t + 1}). 
\]
This is the Euler Equation. The RHS is discounting the marginal utility of capital from next period. $\beta$ is discounting, and $u'$ is the marginal utility of capital.
\end{definition}
It is important that $k$ doesn't appear by itself (will show up later in class).

\rd{REVIEW TWO WAYS TO OBTAIN EULER EQUATION}

Intuition for $f'(k_{t + 1})$: $f(k_{t + 1})$ is the output we can produce next period. $f'$ is the derivative of that production function, and we can think of it as the slope of the production function, or the (limit of) additional output we get divided by the additional capital deployed. $u'$ is the additional utility we get from an additional amount of consumption.

There is only one $k_1$ that will give a sequence, from the Euler equation, that satisfies the /transversality condition/. We have one Euler equation for each $t \ge 0$, so\ldots infinitely many. This isn't good, since we have too many equations! But the Bellman equation doesn't have this problem. How can we get a similar solution for the Euler equations?

\begin{definition}[Transversality Condition]
\[
\lim_{t \to \infty} \beta^t u'(f(k_t) - k_{t + 1}) f'(k_t) \cdot k_t = 0
\]
Working from right to left, this limit is the capital stock, multiplied by the marginal product of capital. Now we want to turn this into utility, so we multiply it by the utility of the output produced from this stock of capital. Finally, we have to discount this back to today, since this is future output/utility. Intuitively, this whole term is the present value of capital that we have in period $t$. As we send the limit to infinity, our future capital is worth nothing. Using this condition allows us to pin down the infinite sequence from the Euler equations. If we choose an arbitrary $k_1$ instead, we can end up with either negative consumption or a negative capital stock, neither of which makes sense. \rd{VERIFY THIS NUMERICALLY}. Mathematically, there is only one $k_1$ that lies on the saddle path.
\end{definition}
 
# \rd{SEE THM 4.15 on page 98 of Stokey and Lucas}
\begin{theorem}[Sufficiency of the Euler and transversality conditions; Stokey and Lucas 4.15]
Let $X \subset \R^l_+$, and let $F$ satisfy the following conditions:
\begin{enumerate}
\item $X$ is a convex subset of $\R^l$, and the correspondence $\Gamma: X \to X $ is non-empty, compact-valued, and continuous.
\item The function $F: A \to \R$ is bounded and continuous, and $0 < \beta < 1$.
\item For each $y$, $F(\cdot, y)$ is strictly increasing in each of its first $l$ arguments.
\item $F$ is strictly concave.
\item $F$ is continuously differentiable on the interior of $A$.
\end{enumerate}
Then the sequence
\[
\{x^*_{t + 1}\}^\infty_{t = 0}, \text{ with } x^*_{t + 1} \in \operatorname{int} \Gamma (x^*_t), t = 0, 1, \ldots
\]
is optimal for the problem
\begin{align*}
\sup_{\{x_{t + 1}\}^\infty_{t = 0}} \sum^\infty_{t = 0} & \beta^t F(x_t, x_{t + 1})\\ 
\text{s.t. } x_{t + 1} &\in \Gamma(x_t), t = 0, 1, 2,\ldots,\tag{SP}\label{SP}\\
\text{given } x_0 & \in X
\end{align*}
if the sequence satisfies
\begin{align*}
0 &= F_y(x_t^\ast, x_{t + 1}^\ast) + \beta F_x(x_{t + 1}^\ast, x_{t + 2}^\ast), \quad t = 0, 1, 2,\ldots\tag{2}\label{LS4.15:2}\\
0 &= \lim_{t \to \infty} \beta^t F_x(x_t^\ast, x_{t + 1}^\ast) \cdot x_t^\ast \tag{3}\label{LS4.15:3}
\end{align*}
\end{theorem}
\begin{proof}
Take $x_0$ as given, assume $\{x_t^\ast\} \in \Pi(x_0)$ satisfies \ref{LS4.15:2} and \ref{LS4.15:3}, and let $\{x_t\} \in \Pi(x_0)$ be any feasible sequence. It is sufficient to show that the difference (call it $D$) between the objective function in \ref{SP} evaluated at $\{x_t^\ast\}$ and $\{x_t\}$ is nonnegative.
\begin{align*}
\intertext{Since $F$ is continuous, concave, and differentiable,}
D &= \lim_{T \to \infty} \sum^T_{t = 0}\beta^t [F(x_t^\ast, x_{t + 1}^\ast) - F(x_t, x_{t + 1})]\\
&\ge \lim_{T \to \infty} \sum^T_{t = 0} \beta^t[F_x(x_t^\ast, x_{t + 1}^\ast)\cdot (x_t^\ast - x_t) + F_y(x_t^\ast, x_{t + 1}^\ast)\cdot (x_{t + 1}^\ast - x_{t+ 1})].\\
\intertext{Since $x_0^\ast - x_0 = 0$, rearranging terms gives}
D &\ge \lim_{T \to \infty}\left\{\sum^{T - 1}_{t = 0} \beta^t[F_y(x_t^\ast, x_{t+1}^\ast) + \beta F_x(x_{t + 1}^\ast, x_{t + 2}^\ast)]\cdot (x_{t + 1}^\ast - x_{t + 1}) + \beta^T F_y (x_T^\ast, x_{T + 1}^\ast)\cdot(x_{T + 1}^\ast - x_{T + 1})\right\}.\\
\intertext{Since $\{x_t^\ast\}$ satisfies \ref{LS4.15:2}, all the terms in the summation are zero. Substituting from \ref{LS4.15:2} into the last term and using \ref{LS4.15:3} gives}
D &\ge - \lim_{T \to \infty} \beta^T F_x(x_T^\ast, x_{T + 1}^\ast)\cdot (x_T^\ast - x_T)\\
&\ge - \lim_{T \to \infty} \beta^T F_x (x_T^\ast, x_{T + 1}^\ast) \cdot x_T^\ast.
\end{align*}
The last line uses the fact that $F_x \ge 0$ (one of our assumptions) and $x_t \ge 0$ for all $t$. It follows from \ref{LS4.15:2} that $D \ge 0$, establishing the desired result.
\end{proof}

** Things to know for exam/course
\begin{enumerate}
\item Contraction mapping theorem
\item Won't be tested on complete metric space, Cauchy sequence; we'll be dealing with specific functional forms that meet our assumptions
\item We are expected to be able to verify the Blackwell Sufficient Conditions
\end{enumerate}

* TA Section---October 9, 2020 (Introduction to Dynamic Programming)

** The Sequential Problem and its Solution

Consider the simple deterministic neoclassical growth model. We don't have prices, just the resource constraint and the capital accumulation equation. We have an infinitely-lived household, so the utility function depends on a sequence of consumption and is time-separable,
\[
\sum^\infty_{t = 0} \overbrace{\beta^t}^{\text{discount factor}} \underbrace{u(c_t)}_{\text{instantaneous utility}}.
\]
The agent chooses a sequence of consumption, capital and investment,
\[
\{c_t, k_{t + 1}, i_t\}^\infty_{t = 0}
\]
subject to
\begin{align*}
c_t + i_t &\le \underbrace{F(k_t, n_t)}_{\text{predetermined output}} \tag{resource constraint}\\
k_{t + 1} &= i_t + \underbrace{(1 - \delta)k_t}_{\scriptsize{\begin{tabular}{c}undepreciated\\capital\end{tabular}}}]\tag{capital accumulation}\\
n_t &\in [0, 1] \tag{labor}\\
c_t, k_t &\ge 0 \frall t\tag{non-negativity constraints}\\
k_o &\text{ given}
\end{align*}

We can substite for investment in our initial problem to get
\[
c_t + \{k_{t + 1} - (1 - \delta) k_t\} = F_{t + 1}.
\]
We can further simplify this so that the only thing we're choosing is a sequence of capital levels. Assuming $\delta = 1$, we get
\[
\max_{\{k_{t + 1}\}^\infty_{t = 0}} \sum^\infty_{t = 0} \beta^t \left(f(k_t) - k_{t + 1}\right)
\]
with $0 \le k_{t + 1} \le f(k_t)$ and $k_0$ given. We can now derive the Euler equation. There are only two terms that depend on $k_{t + 1}$,
\[
\ldots \beta^t u(f(k_t) - f_{t + 1} + \beta^{t + 1} u(f(k_{t + 1}) - k_{t + 2}) \ldots
\]
Now we can take the derivative with respect to $k_{t + 1}$,
\[
\beta^t u' (f(k_t) - k_{t + 1})\cdot -1 + \beta^{t + 1} u'(f(k_+{t + 1}) - k_{t + 2}) \cdot f'(k_{t + 1}).
\]
Simplifying,
\[
\underbrace{u'(f(k_t) - k_{t + 1})}_{c_t} = \beta \underbrace{f'(k_{t + 1})}_{\text{MP}k} \cdot u'(\underbrace{f(k_{t + 1}) - k_{t + 2}}_{c_{t + 1}}).
\]
In words, the marginal cost of forgone consumption today must be the same as the discounted value of tomorrow's marginal product of capital, plus the marginal utility from consuming tomorrow's output.

** Analytic Solution (full depreciation)

\begin{align*}
u(c) &= \log(c)\\
f(k) &= k^\alpha, \quad \alpha \in (0, 1)\\
u'(c) &= \frac{1}{c}\\
f'(k) &= \alpha k^{\alpha - 1}\\
(k_t^\alpha - k_{t + 1})^{-1} &= \beta \alpha k^{\alpha - 1}_{t + 1}(k^\alpha _{ t + 1} - k_{t + 2})^{-1}\tag{Euler Equation}\\
\implies k_{t + 1}^\alpha - k_{t + 2} &= \beta \alpha k_{t + 1}^{\alpha - 1}(k^\alpha_t - k_{k + 1})\\
\intertext{We want}
k_{t + 1} &= g(\underbrace{k_t}_{\text{given}}).\\
\intertext{The limit of the solution to the finite horizon problem is equivalent to the unique solution to the infinite horizon problem.} 
k^\alpha_{t + 1} - k_{t + 2} &= \beta \alpha k^{\alpha - 1}_{t + 1} (k^\alpha_t - k_{t + 1}) \text{ for } t = 1, 2, \ldots , T - 1.\\
\intertext{We have $\underbrace{k_0}_{\text{given}}, k_1, \ldots, K_T$. This leaves us $T$ variables and $T - 1$ equations, so we need to consider the terminal condition,}
\underbrace{\beta^t u'(c_T)}_{> 0} \cdot k_{T + 1} &= 0\\
\implies k_{T + 1} &= 0.\\
\intertext{Consider the Euler Equation for $t = T - 1$,}
k^\alpha_T - k_{T + 1} &= \beta \alpha k_T^{\alpha - 1}(k^\alpha_{T - 1} - k_t)\\
k^\alpha_T &= \beta \alpha k_T^{\alpha - 1}(k^\alpha_{T - 1} - k_T)\\
k_T &= \beta \alpha (k^\alpha_{T - 1} - k_T)\\
\implies k_T &= \frac{\beta \alpha}{1 + \beta \alpha} k^\alpha_{T - 1}\\
\intertext{Iterate on $t = T - 2$,}
k_{T - 1} &= \frac{\alpha \beta (1 - \alpha \beta)}{(1 + \alpha \beta + (\alpha \beta)^2)}k_{T - 2}\\
\intertext{Taking the limit as $t \to \infty$,}
k_{t + 1} &= \frac{\alpha \beta (1 - (\alpha \beta)^{T _ t})}{1 - (\alpha \beta)^{T - t + 1}} k^\alpha_t\\
k_{t + 1} &= \alpha \beta k_t^\alpha.
\intertext{The intuition is that}
\text{savings } &= \text{ investment}\\
&= \alpha \beta k_t^\alpha\\
s/y &= \alpha \beta\\
\text{consumption } &= (1 - \alpha \beta)k^\alpha_t. 
\end{align*}

** The Recursive Problem and its Solution
   Define a real-valued function $V(k)$,
\begin{align*}
V(k_0) &= \max_{\left\{k_{t + 1}\right\}^\infty_{t = 0}} \sum^\infty_{t = 0} \beta^t u(f(k_t) - k_{t + 1})\\
\text{s.t. } 0 &\le k_{t + 1} \le f(k_t)\\
\text{given } &k_0\\
\intertext{We want}
V(k_0) &= \text{Return } + \beta \cdot V(k_1).\\
V(k_0) &= \max_{k_1} \max_{\left\{k_{t + 1}\right\}^\infty_{t = 1}} \sum^\infty_{t = 0} \beta^t u(f(k_t) - k_{t + 1})\\
V(k_0) &= \max_{k_1} \max_{\left\{k_{t + 1}\right\}^\infty_{t = 1}} u (f(k_0) - k_1) + \beta u(f(k_1) - k_2) + \ldots\\
V(k_0) &= \max_{k_1} \max_{\left\{k_{t + 1}\right\}^\infty_{t = 1}} \beta u(f(k_0) - k_1) + \beta \sum^\infty_{t = 1} \beta^t \cdot u(f(k_1) - k_{t + 1})\\
V(k_0) &= \max_{k_1} \beta u(f(k_0) - k_1) + \underbrace{\max_{\left\{k_{t + 1}\right\}^\infty_{t = 1}} \beta u(f(k_0) - k_1) + \beta \sum^\infty_{t = 1} \beta^t \cdot u(f(k_1) - k_{t + 1})}_{\beta \max_{\{k_{t + 1}\}^\infty_{t = 1}} \sum^\infty_{t = 1} u(f(k_t) - k_{t + 1})}\\
V(k_0) &= \max_{k_1} u(f(k_0) - k_1) + \beta V(k_1)\\
V(k) &= \max_{k_1} u(f(k) - k') + \beta V(k')\\
\intertext{Where $k'$ denotes tomorrow's capital stock. The optimal $k'$ is}
0 &= -1\cdot u'(f(k) - k') + \beta V'(k') \\
u'(f(k) - k') &= \beta V'(k')\\
\intertext{Suppose}
V(k) &= A + \frac{\alpha}{1 - \alpha \beta} \ln(k)\\
V'(k) &= \frac{\alpha}{1 - \alpha \beta}\cdot k^{-1}\\
V'(k') &= \frac{\alpha}{1 - \alpha \beta} (k')^{-1}\\
\end{align*}

** Habit Persistence

\[
u(c_t, c_{t - 1})
\]

$c_{t - 1}$ is given in $t$, so it is a state variable. For notational convenience, define $d \equiv c_{t - 1}$.
\[
V(k, d) = \max_{\{c, k'\}} u(c, d) + \beta V(k', d')
\]
subject to the constraints
\begin{align*}
c + k' &= f(k)\\
d' &= c
\end{align*}

** Value Function Iteration (HW in Matlab)

* October 12, 2020
   At the end of class today, we should be able to do everything on assignment 1. 
** Steady State
The steady state stock of capital is some $\overline{k}$ such that
\[
\overline{k} = g(\overline{k}).
\]
We can easily find this value from the Euler Equation:
\begin{align*}
u'(f(k_t) - k_{t + 1}) &= \beta u'(f(k_{t + 1}) - k_{t+2})\cdot f'(k_{t + 1})\\
\intertext{by setting}
k_t &= k_{t + 1}\\
&= k_{t + 2}\\
&= \overline{k}\\
\implies u'(f(\overline{k}) - \overline{k}) &= \beta u'(f(\overline{k}) - \overline{k})f'(\overline{k})\\
\implies \frac{1}{\beta} &= f'(\overline{k})\\
\intertext{where}
f(k) &= F(k, 1) + (1 - \delta) k.
\end{align*}
Does a solution exist? If
\begin{align*}
\lim{k \to 0} f'(k) &= \infty\\
\lim_{k \to \infty} f'(k) &= 1 - \delta\\
&< 1\\
\intertext{ and $f(k)$ is continuously differentiable means that there \gr{must} be a point where}
f'(k) &= 1 - \delta \\
&< 1.
\end{align*}
\rd{TODO: Add graphs}
*** Is $\overline{k} > 0$ unique?
If $f(k)$ us concave, yes---this follows from quasiconcavity and constant returns to scale. See Stokey and Lucas Exercise 4.8 for a more complete explanation.
\begin{align*}
f(k) \text{ concave } \implies f''(k) &< 0\\
\implies \overline{k} &\text{ unique}\\
\intertext{But}
\overline{k} &= 0 \\
\intertext{is also a steady state since}
f(0) &= 0.
\end{align*}
** Maximum Sustainable Capital Stock
  $k^\ast$, the maximum sustainable capital stock, is the largest value of $k$ such that 
\[
f(k) \ge k.
\]
Given assumptions about $f(k)$, $k^\ast$ is a solution to
\[
f(k^\ast) = k^\ast.
\]

For $k$ to \emph{ever} be about $k^\ast$, $k^0 > k^\ast$ (perhaps due to a shift in the production function). If so, $k$ \emph{must} decrease over time until it is less than or equal to $k^\ast$.
\begin{enumerate}
\item We can effectively ignore capital stocks about $k^\ast$.
\item We can ignore consumption above by $\overline{c} = f(k^\ast)$.
\item We can bound utility by $u(\overline{c})$.
\item We can apply the contraction mapping theorem.
\end{enumerate}
Even though we start with an unbounded utility function, we can implicitly bound it without loss of generality. This is important, since it allows us to utilize dynamic programming arguments. In order to be able to formally prove that a solution exists, we need to put an upper bound on utility since the function itself doesn't have an upper bound. From a practical standpoint, in terms of solving a dynamic programming problem, this maximum sustainable capital stock is really useful (in particular for solving Problem 3 on Assignment 1, which is graded and required).
 
** Dynamics of the Growth Model
How $k_t$ evolves from $k_0 > 0$ depends on the policy function, $g(k)$. What do we know about this function? We don't assume anything about the policy function; we have to derive/solve for this policy function. But we still know two useful facts about the policy function that will help us solve this problem.
\begin{enumerate}
\item $g(0) = 0$
\item Must cross the $45$ degree line only once for $k > 0$ since $\overline{k}$ is unique.
\end{enumerate}
We can also show that the policy function is increasing and we can bound its slope, but we won't use those facts today.

The key to dynamics is whether $g(k) > k$ for arbitrarily small $k > 0$. Suppose $g(k) < k$ for small $k$. $\overline{k}$ exists, so $g(k)$ must cross the $45$ degree line. If $k_0 < \overline{k}$, then
\[
\lim_{t \to \infty} k_t = 0,
\]
but this contradicts optimization. This means killing off the economy over time, which gives $-\infty$ utility, since the marginal utility of capital near $k = 0$ is very very high. Hence, for arbitrarily small $k$,
\[
\lim_{t \to \infty} k_t = \overline{k},
\]
so $\overline{k}$ is a stable steady state. We say that this steady state is stable because $g(k)$ crosses the $45$ degree line from above.

\textbf{Key Takeaway:} $g(k)$ must cross the $45$ degree line from above!

** Adding Labor-Leisure Tradeoff

This ingredient is key to the real business cycle literature. The RBC model is the neoclassical growth model with a labor-leisure tradeoff and a stochastic shock that affects technology (will cover this in more detail later). For now we're just adding a positive-utility alternative to working. Depending on how we specify $u$, households may not spend all of their time working. In this class we'll always be working with a functional form for $u$, but this isn't necessary in general.

\begin{align*}
\max \sum^\infty_{t = 0} &\beta^t u(c_t, 1 - h_t)\\
\intertext{subject to}
c_t + k_{t + 1} &= F(k_t, h_t) + (1 - \delta) k_t
\end{align*}

We can make assumptions about $u$ to guarantee an interior solution where $0 < h < 1$. Writing this as a dynamic programming problem,
\begin{align*}
V(k) &= \max_{k', h} \left\{u(c, 1 - h) + \beta V(k')\right\}\\
\text{s.t. } c + k' &= F(k, h) + (1 - \delta)k\\
\text{given } &k_0.
\end{align*}
Why don't we include $h$ as a state variable? Because we do not need $h_0$ to solve the sequence problem! $h_0$ is determined in period 0 and has no impact on the problem in period 1. For dynamic programming, it's important to know what's a state variable and what's a choice variable. $h$ is a choice variable; it is chosen within the period and we don't need to know it to solve the problem. We have a static first order condition for $h$.
\begin{align*}
u_2(c, 1 - h) &= u_1(c, 1 - h)F_2(k, h)\\
\intertext{and we can solve for}
h &= \mathcal{H}(k, k')\\
\intertext{We can write the Bellman Equation,}
V(k) &= \max_{k'}\left\{u(c, 1 - \mathcal{H}(k, k')) + \beta V(k')\right\}\\
\text{s.t. } c + k' &= F(k, \mathcal{H}(k, k')) + (1 - \delta)k.
\end{align*} 
This problem fits into the structure from Stokey and Lucas! We can do this, since we know that $h_t$ will be chosen in exactly the same way in each period; $\mathcal{H}$ will be the same function in each period. From a mathematical point of view, it's irrelevant that we choose $h$ each period, since we always choose it in the same way. In general, let
\begin{align*}
S &= \text{ vector of state variables} \tag{need to have $s_0$}\\
d &= \text{ vector of decision variables}\\
V(S) &= \max_d \left\{R(S, d) + \beta V(S')\right\}\\
\text{s.t. } S' &= C(S, d)\\
V'(S) &= R_S (S, d) + \beta V'(S') B_S(S, d) \tag{Envelope Condition}
\end{align*}
This notation and approach are necessary for Problem 2 in Assignment 1. We need to simultaneously consider the static and dynamic first order conditions to solve for both $k$ and $h$. In the Envelope Condition we're holding $d$ constant (since it's a partial derivative); the idea being that we're holding the decision variable constant. But $S$ affects $S'$ as well, so the Envelope Condition doesn't allow us to directly identify $V'(S)$ (due to the chain-rule aspect of the problem). Ideally we want to invert
\[
S' = B(S, d)
\]
so that $S'$ is a choice variable along with a subset of the decision variables. We can't hold $S'$ constant since it isn't chosen directly. We want to rewrite the problem so that $S$ doesn't appear in two different places in our optimization problem.

** Problem 3, Assignment 1
   The code should be very short; it's a straightforward problem to solve. Here's a sketch for how to solve this problem, which is important since it's (a simplified version of) how to solve problems like this in real life. 

*** Solving a Dynamic Program where the state space has a finite number of elements
If capital is on a grid and there is a maximum sustainable capital stock, 
\[
k = \left\{k_1, k_2, \ldots, k_N\right\}.
\]
\textbf{Math notation below is matlab syntax.}
\begin{enumerate}
\item Tabulate the return function $R(k, k')$
\begin{itemize}
\item $R$ is an $N \times N$ matrix: $k'$ rows, $k$ columns
\item Initialize as a matrix of large negative numbers
\item Replace the value of $R$ for $k, k'$ combination that are feasible:
\begin{align*}
k' &< k^\theta \tag{$c$ positive}\\
\implies R(k, k') &= \log(k^\theta - k')
\end{align*}
\item If the $k, k'$ combination isn't feasible, don't change that entry in $R$
\end{itemize}
\item Value Iteration
\begin{itemize}
\item start with $v_0 = N \times 1$ vector of zeroes
\item Form $Tv_0$ ($N \times 1$ matrix) as follows:
\[
[tV(i, 1), g(i, 1)] = \max (R(:, i) + \beta V)
\]
for $i = 1, \ldots, N$. Here $g(i, 1)$ is the row number corresponding to $\max$.
\item Iterate until
\[
\max(\operatorname{abs}(V - tV)) < .00001
\]
\end{itemize}
\end{enumerate}

\noindent \textbf{End of deterministic growth; will start stochastic growth next class.}
* October 14, 2020
** Stochastic Growth
The sequence problem is
\begin{align*}
\max E &\sum^\infty_{t = 0} \beta^t u(c_t)\\
\intertext{subject to}
c_t + k{t + 1} &= z_t f(k_t)\\
z_0, k_0 &\text{ given}.
\end{align*}
The new ingredient is $z$, which is a stochastic shock to technology. $\{z_t\}^\infty_{t = 0}$ is a stochastic process where $z_t$ is observed at the beginning of period $t$. What is being chosen at $t = 0$? We're choosing ``contingent claims''; next period capital given shocks until date $t$. Essentially we're making choices contingent on every possible realization until date $t$. Since there are so many things to choose, the recursive approach is very convenient here. We are going to make assumptions so that we don't need to keep track of the entire history.
\[
\left\{k_{t + 1}(z_0, \ldots ,z_t)\right\}^\infty_{t = 0}
\]
The resource constraint must be satisfied for every possible realization. The recursive formulation is extremely useful. Suppose $Z \overset{\text{iid}}{\sim} G(z)$. Then
\[
v(z, k) = \max_{k'} \left\{u(\underbrace{zf(k) - k'}_{\text{known at }t}) + \beta \int_{z'} v(z', k')dG(z')\right\}.
\]
$dG(z')$ is the density of $z'$; we're weighting our integration by the frequency of outcomes. Note that $z$ is part of the state since it is observed before any decisions are made. We can solve this problem by applying the contraction mapping theorem as before and iterate on the Bellman mapping. The only difference is that we need to compute the expected value for the second term on the right hand side. We assume that $z$ follows a Markov process:
\[
\p(z_{t + 1} \in A \mid z_j (j \le t)) = \p(z_{t + 1} \in A \mid z_t).
\]
This means that we can ignore the infinite history and just focus on the current state.
Some examples:
\begin{enumerate}
\item First order autoregressive process,
\[
z_{t + 1} = \rho z_t + \varepsilon_{t + 1}, \quad \varepsilon_{t + 1} \text{ iid}
\]
\begin{itemize}
\item $\rho = 1 \implies$ iid
\item $\rho = 1 \implies$ random walk
\end{itemize}
\item Markov chain $\iff$ there are a fininte number of possible values of $z$.
\end{enumerate}
Is this condition unreasonably restrictive?
\begin{align*}
\intertext{Suppose}
z_{t + 1} &= \rho_1 z_t + \rho_2 z_{t - 1} + \varepsilon_{t + 1}.\\
\intertext{Then we can let}\\
\tilde{z}_t &= \begin{bmatrix}z_t\\z_{t + 1}\end{bmatrix}\\
&= A\\
\implies \tilde{z}_{t + 1} &= \begin{bmatrix}\rho_1 & \rho_2 \\ 1 & 0\end{bmatrix} \tilde{z}_t + \begin{bmatrix}\varepsilon_{t + 1}\\ 0\end{bmatrix}\\
\implies \tilde{z}' &= A\tilde{z} + B \varepsilon', \quad B=\begin{bmatrix}1\\0\end{bmatrix}
\end{align*}
The Markov assumption just means that information relevant to today's decisions consists of a finite set of realizations from the past.
*** Markov Chains
Stokey and Lucas, 319--334;\quad Ljungquist and Sargent, Chapter 2
\begin{enumerate}
\item Let $S$ be a state space consisting of $n$ (finite) elements, $S_1, \ldots , S_n$.
\item Let $P$ be an $n \times n$ matrix where
\begin{itemize}
\item $\sum^n_{j = 1} p_{ij} = 1$ for $i = 1, \ldots, n$ (rows sum to $1$)
\item $p_{ij} \ge 0$ for all $i, j$
\end{itemize}
Each row of $P$ is a probability distribution. In particular,
\[
p_{ij} = \p(z_{t + 1} = S_j \mid z_t = S_i).
\]
$P$ is called the transition probability matrix.
\item Let $\Pi_0$ be an $n \times 1$ vector where $\Pi_{0i} \ge 0$ for all $i$, and $\sum^n_{i = 1} \Pi_{0i} = 1$. This is the \gr{initial distribution}, where
\[
\Pi_{0i} = \p(z_0 = S_i).
\]
\textbf{Note:} For the stochastic growth model, $z_0$ is given. Hence $\Pi_{0i} = 1$ for some $i$.
\end{enumerate}
$S, P$ and $\Pi_0$ define a Markov Chain. $P^m$ is a transition probability matrix. In particular, 
\[
P^m_{ij} = \p(z_{t + m} = S_j \mid z_t = S_i).
\]
\begin{proof}
Consider $P^2$.
\begin{align*}
P^2_{ij} &= \sum^n_{k = 1} P_{ik} P_{kj}\\
&= \sum^n_{k = 1} \left(\p(z_{t + 1} = S_k \mid z_t = S_i)\cdot \p(z_{t + 2} = S_j \mid Z_{t + 1} = S_k)\right) 
\end{align*}
$\implies P^2$ is a transition probability matrix. Recursively multiplying $P^2$ and $P$ can get any $P^m$.
\end{proof}
Denote the transpose of $P$ by $P^T$. Given $\Pi_0$, the unconditional distribution of $z$ at date $t$ is given by
\[
\Pi_t = (P^T)^t \Pi_0.
\]
\begin{proof}
\begin{align*}
\Pi_1 &= P^T \Pi_0 \tag{convince yourself}\\
\Pi_{t + 1} &= P^T \Pi_t \tag{convince yourself}\\
\intertext{Recursively applying this formula,}
\Pi_2 &= P^T\Pi_1\\
&= (P^T)^2 \Pi_0\\
&\vdots\\
\Pi_t &= (P^T)^t \Pi_0
\end{align*}
\end{proof}
This transition matrix is the thing we're interested in. Next class, we're going to apply this idea to the entire stochastic growth model so that we can characteristic the unconditional probability of the capital stock being a particular value. Then we can take the limit and see what the capital stock and other endogenous variables look like in the limit.
\paragraph{Two important concepts}
\begin{enumerate}
\item An invariant (ergodic, stationary) distribution is some $\Pi$ such that $\Pi = P^T \Pi$. This is the stochastic analog of a steady state.
\item A limit distribution is some $\Pi_\infty$ where
\begin{align*}
\Pi_\infty &= \lim_{t \to \infty} \Pi_t \\
&= \lim_{t \to \infty} (P^T)^t \Pi_0
\end{align*}
\end{enumerate}
\paragraph{Note}
\begin{enumerate}
\item If $\Pi_\infty$ exists and $\lim_{t \to \infty} (P^T)^t$ has identical columns, $\Pi_\infty$ is unique (does not depend on $\Pi_0$).
\item Any limit distribution is an invariant distribution, and any invariant distribution is a limit distribution for some $\Pi_0$. This is because an invariant distribution, if it exists, may not be unique.
\item Solving for an invariant distribution:
\begin{align*}
\Pi &= P^T \Pi\\
\implies 0 &= (I - P^T)\Pi\\
\intertext{$\implies \Pi$ is a normalized (elements sum to $1$) eigenvector associated with a unique eigenvalue of $P^T$.}
\end{align*}
\end{enumerate}
\paragraph{Goal: } Determine when there is one and only one invariant distribution. If this is the case, the limit distribution is unique and independent of $\Pi_0$.
\begin{definition}[Ergodic Set]
A set $E \subseteq S$ is called an \gr{ergodic set} if
\[
\p(z' \in E \mid z = z_i) = 1
\]
for any $z_i \in E$ and if no proper subset of $E$ has this property.
\end{definition}
To reach our goal, we need to consider some examples of Markov chains. First, how do we solve the planner's problem if $z$ is governed by a Markov chain? Suppose
\begin{align*}
z' &\in \{z_L, z_H\}\\
\intertext{with transition matrix}
P &= \begin{bmatrix}q & 1 - 1\\1 - q & q\end{bmatrix}\\
v(z, k) &= \max_{k'} \left\{u(zf(k) - k') + \beta Ev(z', k')\right\}\\
\intertext{Set up the Bellman equation, first defining}
v_L(k) &\equiv v(z_L, k),\\
v_H(k) &\equiv v(z_H, k).\\
Tv_L(k) &= \max_{k'} \left\{u(z_L f(k) - k') + \beta[qv_L(k') + (1 - q)v_H(k')]\right\}\\
Tv_H(k) &= \max_{k'} \left\{u(z_H f(k) - k') + \beta[(1 - q)v_L(k') + q v_H(k')]\right\}.\\
\intertext{Find the two functions, $v_L$ and $v_H$, that are a fixed point of this mapping. Similar to earlier, guess a functional form, and if the Bellman Mapping is closed under the functional form, use the method of undetermined coefficients.}
\end{align*}
Later, how do we characterize the limit distribution---the stochastic analog of the steady state?
*** Examples
    \begin{enumerate}
\item
\[
P = \begin{bmatrix}
q & 1 - q\\
1 - 1 & q
\end{bmatrix}
\]
\begin{enumerate}
\item $0 < q < 1 \implies$ there is only one ergodic set, $\{z_L, z_H\}$, since $P_{ij} > 0$ for all $i, j$. Solve $\Pi = P^T\Pi \implies \Pi = \begin{bmatrix}\frac{1}{2} \\ \frac{1}{2}\end{bmatrix}$, which is the unique solution/distribution.
\end{enumerate}
\item 
\[
q = 1 \implies P = \begin{pmatrix} 1 & 0 \\ 0 & 1\end{pmatrix}
\]
In this case, there are $2$ ergodic sets,
\[
E_1 = \{Z_L\},\quad E_2 = \{Z_H\}.
\]
Each state is an \gr{absorbing state}; once you get to that state you never get out. In this case, any $\Pi$ is an invariant distribution. Note that
\[
\Pi_\infty = \lim_{t \to \infty} (P^T)^t \Pi_0 = \Pi_0.
\]
\item 
\[
q = 0 \implies P = \begin{bmatrix}0 & 1 \\ 1 & 0\end{bmatrix}
\]
There is one ergodic set,$\{z_L, z_H\}$.
\end{enumerate}


* October 19, 2020
  Our graded homework assignment will be due on Friday, October 30. We already have the first two problems, and will have the third one soon. \rd{Do problem 1 tomorrow.}
** Examples of Markov Chains
\begin{enumerate}
\item[2.]
\[
P = \begin{bmatrix}
0.7 & 0.2 & 0.1 \\
0 & 0.5 & 0.5 \\
0 & 0.9 & 0.9
\end{bmatrix}
\]
How many ergodic sets? remember we can't use the whole state space as an ergodic set. Therefore we only have one ergodic set,
\[
E = \{Z_2, Z_3\}.   
\]
We call $Z_1$ a \gr{transient state} since it has probability $0$ in the limiting distribution. We want to be able to break down Markov chains into ergodic sets and transient states (this is common on exams, and there is an example on the assignment).
\item[3.] Let $P_1$ be an $m \times m$ matrix with all positive elements, $P_w \ldots (n - m)\times (n - m) \ldots$,
\[
P = \begin{bmatrix}
P_1 & 0 \\
0 & P_2
\end{bmatrix}_{n \times n},
\]
where $P$ is an $n \times n$ matrix and $P_1$ and $P_2$ each define a Markov chain on their own ($P_1$ and $P_2$ are transition probability matrices). This setup gives us two ergodic sets,
\begin{align*}
E_1 &= \{Z_1,\ldots , Z_m\}, \text{ and}\\
E_2 &= \{Z_{m + 1}, \ldots , Z_n\}. 
\end{align*}
In this case, we don't have any transient states. An invariant distribution for Markov chain $P$ is some $\Pi$ such that
\[
\Pi = a \begin{bmatrix}
\Pi_1 \\ 0
\end{bmatrix} + (1 - a)
\begin{bmatrix}
0 \\ \Pi_2
\end{bmatrix},
\]
where $\Pi$ is the unique invariant distribution of $E_1$, and $\Pi_2$ is the unique invariant distribution of $\Pi_2$. This definition holds for any $a \in [0, 1]$. We can think of $a$ as the probability weight assigned to the first ergodic set in the initial distribution,
\[
a = \sum^m_{i = 1}\pi_{0i}.
\]
\item[4.]
This is the general case of cyclically moving subsets. Let $P_1$ be an $m \times(n - m)$ matrix $P_2 \ldots (n - m) \times m \ldots$,
\[
P = \begin{bmatrix}
0 & P_1 \\
P_2 & 0
\end{bmatrix}.
\]
The limiting distribution here does not exist (the way we defined it) for most initial distributions since we end up switching between the two states.
\end{enumerate}
When does a Markov chain have a unique invariant distribution?
\begin{theorem}
Let $Z = \{z_1, \ldots, z_n\}$ and $P$ be a corresponding transition probability matrix. $P$ has a unique ergodic set if and only if there exists a state $z_j \in Z$ such that, for every $i \in \{1, \ldots, n\}$, there exists a $t \ge 1$ such that $p_{ij}^{(t)} > 0$. In this case, the invariant distribution is unique.
\end{theorem}
In words, we can get to every $z_j$ from $z_i$ infinitely many times with positive probability. This does not rule out cyclically moving subsets. To check potential limiting distributions, we only need to look at states we can get to from anywhere else in the state space.
\begin{corollary}
If $p_{ij} > 0$ for all $i, j$, then there is a unique stationary distribution  and no cyclically moving subsets.
\end{corollary}
This won't work in our stochastic growth model because our transition matrix will have lots of zeroes. This corollary also eliminates transient states, which are an important feature of the stochastic growth model.
** Application to the stochastic growth model
\begin{align*}
V(z, k) &= \max_{k' \in K} \{u(f(k) - k') + \beta E V(z', k')\}\\
\text{s.t.\quad} z' &\in \{z_L, z_H\} \\
\intertext{with transition matrix}
P &= \begin{bmatrix}q & 1 - q\\1 - q & q\end{bmatrix} \tag{$q \in (0, 1)$}\\
K &= \{K_1, K_2, \ldots, K_n\}
\end{align*}
We can solve for the policy function
\begin{equation*}
k' = g(z, k ) = \left\{
\begin{array}{ll}
g_L(k) & \text{ if }z = z_L\\
g_H(k)  & \text{ if }z = z_H\\
\end{array}
\right.
\end{equation*}
Form a $2n \times 2n$ transition probability matrix (the size of the state space) $\hat{P}$ as follows. Let $S$ be the set of all $z, k$ combinations.
\begin{align*}
S_2 &= (z_L, K_1)\\
S_2 &= (z_L, K_2)\\
&\vdots \\
S_n &= (z_L, K_n)\\
S_{n + 1} &= (z_H, K_1)\\
&\vdots \\
S_{2n} &= (z_H, K_n)
\end{align*}
Lots of these are going to be zeros since we'll never jump from the lowest $K$ to the highest $K$ in one period. There's a positive probability we can get to a high capital state eventually, but it will take many periods of investment to get there. This is why the stochastic growth model violates the condition from our earlier corollary. With this setup,
\begin{align*}
\hat{P}_{ij} &= \p (z' = S_{j1} \mid z = S_{ij})\cdot \p(k' = S_{j2}\mid S_i )\\
&= P_{S_i, S_{j1}} \cdot X(g(S_i) = S_{j2}),\\
\intertext{where}
X(\text{statement}) &= \left\{
\begin{array}{ll}
1 & \text{ if statement is true}\\
0 & \text{ if statement is false}
\end{array}
\right.\\
\intertext{We can find an invariant distribution by solving}
\hat{\Pi} &= \hat{P}^T \hat{\Pi}.
\end{align*}
We can use $\hat{\Pi}$ to compute any statistic of interest.
\begin{example}[Compute the standard deviation of output]
\begin{align*}
y &= F(k, 1)\\
\sigma_y &= \sqrt{Ey^2 - (Ey)^2}\\
Ey &= E (z F(k_1))\\ &= \sum^{2n}_{i = 1} \hat{\pi}_1 S_{i1}F(S_{i2}, 1)\\
Ey^2 &= E(zF(k, 1))^2\\ &= \sum^{2n}_{i = 1} \hat{\pi}_i (S_i, F(S_{i2}, 1))^2
\end{align*}
\end{example}
There are three ways to show that the invariant distribution is unique:
\begin{enumerate}
\item $\hat{P}^T$ has one and only one unit eigenvalue.
\item All of the rows of $\lim_{t \to \infty} \hat{P}^t$ are identical.
\item Use a theorem given the shape of the policy function
\end{enumerate}
\rd{ADD GRAPHS WITH POLICY FUNCTIONS AND THEIR SHAPES.}


$E = [k_L, k_H]$ is the unique ergodic set for capital. The conditions for our theorem are satisfied for any state $S$ where $k = K_j$ for $k_L \le K_j \le k_H$. In words, we can pick any element of the grid between $k_L$ and $k_H$ and any state. The only restriction is that we are in the ergodic set.  This solution assumes that $k$ is on a grid.
\begin{example}
\begin{align*}
V(z, k) &= \max_{k'}\{\log(e^z k^\theta - k') + \beta V(z', k'))\}\\
Z &\sim N(0, \sigma^2).
\end{align*}
Characterize the limit distribution of $\log k$ and $\log y$. Is it unique? In other words, does it depend on $z_0$ and/or $k_0$? This problem will be part of our graded homework. \textbf{Hints:}
\begin{enumerate}
\item The normal distribution is fully characterized by its mean and variance.
\item Do problem 2.7 in Stokey and Lucas. In this more complicated problem we will also have to calculate the policy function.
\end{enumerate}
Here, we are able to find a closed form solution for the stationary distribution. We could also do the same thing when the state space has a finite number of elements. In most interesting cases, this is impossible.
\end{example}
** Using Simulation (Law of Large Numbers) to characterize the invariant distribution
   Given 
\begin{align*}
k_{t + 1} &= g(z_t, k_t)\\
\intertext{and values for $z_0$ and $k_0$,}
Z_{t + 1} &\sim G(z' \mid z_t)
\end{align*}
\begin{enumerate}
\item Draw $z_t, t = 1, \ldots, T_0$ using a random number generator.
\item Compute $\{k_t\}^{T_0}_{t = 1}$ using $k_{t + 1} = g(z_t, k_t)$.
\item Discard everything except $z_{T_0}$ and $k_{T_0}$ to remove any dependence on the initial condition.
\item Repeat steps $1$ and $2$ setting $z_0 = z_{T_0}$ and $k_0 = k_{T_0}$ to obtain $\{z_t, k_t\}^T_{t = 0}$, where $T$ is large.
\item Compute the statistic of interest,
\[
E \phi (z, k) \approx \frac{1}{T} \sum^T_{t = 1} \phi(z_t, k_t),
\]
where $\phi(z, k)$ is some function of $z$ and $k$.
\end{enumerate}

* October 21, 2020
* Relationship between AR and MC
   \begin{equation}
Z_{t + 1} = \rho z_t + \varepsilon_{t + 1}, \quad \varepsilon_{t + 1} \sim \mathcal{N}(0, \sigma_\varepsilon^2)\tag{AR}
   \end{equation}
Assume we also have a two state Markov chain, $z \in \{z_L, z_H\}$, with transition matrix $P$.

\begin{problem}
Assume we are given values for $\rho$ and $\sigma_\varepsilon$. Find values for $z_L, z_H$, and $P$ so that the first and second moments are the same for both stochastic processes.
\end{problem}
Here's a start\ldots
\begin{enumerate}
\item (AR) is a symmetric stochastic process. In the limit, we spend equal time both above and below the mean, $\implies$
\[
P = \begin{bmatrix}q & 1 - q\\ 1 - q & q\end{bmatrix}
\]
\item
\[
Ez = 0 \implies z_L = -\sigma \text{ and } z_H = \sigma
\]
\end{enumerate}
So, we need to find values for $\sigma$ and $q$ that match second moments.

\paragraph{Answer.}
\[
q = \frac{1 + \rho}{2}, \quad \sigma = \frac{\sigma_\varepsilon}{\sqrt{1 - \rho^2}}
\]
\rd{Add graphs from class (after doing calculations/simulations) time permitting.}

** General Equilibrium
So far, we have studied solutions to the planner's problem. These allocations are also an equilibrium allocation where quantities are chosen by households and firms, and prices clear markets. This result follows from the Second Welfare Theorem. Mostly, we are interested in equilibria in economies with distortions (for example taxes and externalities). We are also interested in prices---usage rates, rental rates, the interest rate, asset prices, etc. How do we model a decentralized economy and define an equilibrium? There are three main approaches.

#+ATTR_LATEX: :booktabs t
|-----------------------+------------------------------------------------------------------|
| Arrow-Debreu          | Very general and abstract.                                       |
|                       | Prices don't correspond to prices in the real world.             |
|-----------------------+------------------------------------------------------------------|
| Sequence of Markets   | Popular in asset pricing.                                        |
|                       | Prices correspond to their real world problem.                   |
|                       | Agents solve a sequence problem.                                 |
|-----------------------+------------------------------------------------------------------|
| Recursive Competitive | An alternative sequence of markets approach.                     |
| Equilibrium           | Households solve a dynamic program.                              |
|                       | This approach has the advantage of suggesting a solution method. |
|-----------------------+------------------------------------------------------------------|


\begin{example}[Sequence of Markets approach]
There are $N$ identical households and one firm with CRS technology (WLOG).
\begin{enumerate}
\item[\textbf{Markets.}] Markets are held \textbf{each} period.
\item[\textbf{Goods.}] Supplied by the firm, demanded by households. Price$= 1$ (numeraire).
\item[\textbf{Labor.}] Supplied by households, demanded by firms. Price$_t = w_t$. Each household is endowed with 1 unit of time each period, which they can use for either labor or leisure.
\item[\textbf{Capital.}] Accumulated and owned by households, who rent capital to firms. Rental Price$_t = r_t$.
\item[\begin{tabular}{r}\textbf{Household's}\\ \textbf{Problem.}\end{tabular}]
\begin{align*}
\max \sum^\infty_{t = 0} & \beta^t u(c_t, 1 - h_t)\\
\intertext{subject to}
c_t + i_t &= w_t h_t + r_t h_t\\
k_{t + 1} &= (1 - \delta)k_t + i_t\\
k_0 &\text{ given}
\end{align*}
The household is now subject to a budget constraint, not a resource constraint. Unlike a resource constraint, a budget constraint involves prices.
\item[\textbf{Firm's Problem.}]
\begin{align*}
\max &\{y_t - w_t h_t - r_t k_t\},\quad t = 0, 1, 2, \ldots\\
\intertext{subject to}
y_t &= F(k_t, h_t)
\end{align*}
The firm solves a static problem---all the dynamics are in the household's problem. The firm solves the same problem each period; they're renting capital and paying labor for each period. Nothing (for the firms) carries through each period. The assumption that households own capital and firms rent it means that the firm solves a static problem.
\end{enumerate}
\end{example}time
\begin{definition}[Competitive Equilibrium]
A \gr{competitive equilibrium} is
\begin{enumerate}[label=(\alph*)]
\item An allocation for households
\[
\{c_t^d, i_t^d, k_t^s, h_t^s\}^\infty_{t = 0}
\]
\item An allocation for firms
\[
\{h_t^d, k_t^d, y_t^s\}^\infty_{t = 0}
\]
\item Prices
\[
\{w_t, r_t\}^\infty_{t = 0}
\]
\end{enumerate}
such that
\begin{enumerate}
\item Given $\{w_t, r_t\}^\infty_{t = 0}$, the household allocation solves the household's problem (given prices).
\item Given $\{w_t, r_t\}^\infty_{t = 0}$, the firm's allocation solves its problem for $t = 0, 1, 2, \ldots$ (given prices).
\item Markets clear:
\begin{align*}
h_t^d &= Nh_t^s \tag{Labor markets}\\
k_t^d &= Nk_t^s \tag{Capital rental}
\end{align*}
\end{enumerate}
\end{definition}

The goods market is guaranteed to clear,
\[
y_t^s = N(c_t^d + i_t^d),
\]
by Walras' Law.

In this notation, the $d$ and $s$ superscripts denote ``demand'' and ``supply''. The household problem is a sequence problem; the firm's problem is a \emph{sequence of problems}, because it is static.
\begin{exercise}
Show that, in a $T$-period version of this economy, the social planner's allocation and the equilibrium allocations are identical.
\end{exercise}
\begin{exercise}[Walras' Law]
Prove Walras' Law for this economy. Show that, if the labor and capital markets are in equilibrium, the goods market automatically clears.
\end{exercise}

* October 26, 2020 
** Recursive Competitive Equilibrium (same economy)
In this setup, the allocations and prices are functions rather than sequences. First, notice that
\begin{enumerate}
\item From the first order conditions of the sequence version of the firm's problem,
\begin{align*}
w_t &= F_2(k_t, h_t)\\
r_t &= F_1(k_t, h_t)
\end{align*}
\item The first order condition for $h_t$ in the household's problem is
\[
u_2(c_t, 1 - h_t) = u_1(c_t, 1 - h_t)w_t
\]
\item
\[
c_t = w_t h_t + r_t k_t + (1 - \delta)k_t - k_{t + 1}
\]
\end{enumerate}
Combining these three conditions, we obtain
\[
h_t = \mathcal{H}(k_t, k_{t + 1}).
\]
Let $\{K_t\}^\infty_{t = 0}$ be the equilibrium sequence of (per capita) capital stock. Then,
\[
H_t = \mathcal{H} (K_t, K_{t + 1}).
\]

The household's problem is
\begin{align*}
v(K, k) &= \max_{h, k'} \{u(c, 1 - h) + \beta v(K', k')\}\\
\intertext{subject to}
c + k' &= wh + rk + (1 - \delta)k\\
w &= w(K)\\
r &= r(K)\\
K' &= G(K) \tag{perceived law of motion}
\end{align*}

The firm's problem is
\begin{align*}
\max_{k', h'} &\{F(k^t, h^t) - wh^f - rk^f\}\\
\intertext{subject to}
w &= w(K)\\
r &= r(K)
\end{align*}

\begin{definition}[Recursive Competitive Equilibrium]
A \gr{recursive competitive equilibrium} is 
\begin{enumerate}[label=(\alph*)]
\item Decision rules for households,
\[
h(K, k), \quad k'(K, k),
\]
\item Decision rules for the firm,
\[
h^f(K),\quad k^f(K),
\]
\item Pricing functions,
\[
w(K),\quad r(K),
\]
\item And a perceived law of motion,
\[
G(k)
\]
\end{enumerate}
such that
\begin{enumerate}
\item Given $w(K), r(K)$ and $G(K)$, the decision rules for the households solve the household's dynamic program.
\item Given $w(k)$ and $r(k)$, the firm's decision rules solve the firm's problem.
\item Markets clear,
\begin{align*}
Nh(K, K) &= h^f(K)\\
NK &= k^f(K).
\end{align*}
\item Rational expectations,
\[
k'(K, K) = G(K).
\]
\end{enumerate}
\end{definition}
